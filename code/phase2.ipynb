{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IqW2S5FEl0Q"
      },
      "source": [
        "# **`Checking GPU availability`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA_ierau5Yiq",
        "outputId": "f9710e71-2dff-45e0-98df-73403d05a95f"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Apr 13 16:08:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-p1ezcbE9Xy"
      },
      "source": [
        "# **Checking RAM availability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twDzSRoA5akd",
        "outputId": "91c25833-fdc9-45ad-b090-9e38c026cc84"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2vOYq2-FOZk"
      },
      "source": [
        "# **Importing Libraries and Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiiEqB9jfoPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af087c50-d9ad-4f9d-bac8-8f3a84a4c852"
      },
      "source": [
        "!pip install torchtext==0.6.0 --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "#from torchtext.data.metrics import bleu_score\n",
        "#from pprint import pprint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#from torchsummary import summary\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 15.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzqGMrfKgBY_",
        "outputId": "8341ac68-322a-4e80-9c2f-eeacc5ca6ed6"
      },
      "source": [
        "!python -m spacy download en --quiet\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMbYNYEOgr4W",
        "outputId": "8ffbd5af-71b4-4d75-a54c-00ab8a7516cd"
      },
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'indic_nlp_library' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co3WuyQCj21R",
        "outputId": "ed8a28be-c799-4b31-9b74-2da09c5b5667"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'indic_nlp_resources' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMilEI-AkEVX"
      },
      "source": [
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZwMAo5DkIu_"
      },
      "source": [
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFrXwVlJkMiW"
      },
      "source": [
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkc_LZHBkRAs"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzBkWOmjkh-D",
        "outputId": "15a50f39-10d2-4c63-afb7-b2637b378bac"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "\n",
        "indic_string='सुनो, कुछ आवाज़ आ रही है। फोन?'\n",
        "\n",
        "print('Input String: {}'.format(indic_string))\n",
        "print('Tokens: ')\n",
        "for t in indic_tokenize.trivial_tokenize(indic_string): \n",
        "    print(t)\n",
        "\n",
        "print(indic_tokenize.trivial_tokenize(indic_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input String: सुनो, कुछ आवाज़ आ रही है। फोन?\n",
            "Tokens: \n",
            "सुनो\n",
            ",\n",
            "कुछ\n",
            "आवाज़\n",
            "आ\n",
            "रही\n",
            "है\n",
            "।\n",
            "फोन\n",
            "?\n",
            "['सुनो', ',', 'कुछ', 'आवाज़', 'आ', 'रही', 'है', '।', 'फोन', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI_IDzqeFb8G"
      },
      "source": [
        "# **Mounting Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaTgu_PekttC",
        "outputId": "00e7c72b-7761-4d00-9cae-814b42902f8c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "377e9yx_k3AL"
      },
      "source": [
        "spacy_english = spacy.load(\"en\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6rMsqxjFnG5"
      },
      "source": [
        "# **Defining Tokenizers for English (spacy) and Hindi (Indic NLP)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQoG4ibSlXIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650818b4-d751-4928-e8a2-2d595108a1ba"
      },
      "source": [
        "def tokenize_english(text):                  #tokenizer for english using Spacy\n",
        "  return [token.text for token in spacy_english.tokenizer(text)]\n",
        "\n",
        "\n",
        "sample_text = \"I am, going to work\"\n",
        "print(tokenize_english(sample_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', ',', 'going', 'to', 'work']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqRX3f17lJpA",
        "outputId": "00d95afb-ba74-46bb-9dc1-ec5b679a0e81"
      },
      "source": [
        "def tokenize_hindi(text):                      #tokenizer for hindi using Indic NLP\n",
        "  return indic_tokenize.trivial_tokenize(text)\n",
        "\n",
        "sample_text = 'सुनो, कुछ आवाज़ आ रही है। फोन?'\n",
        "print(tokenize_hindi(sample_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['सुनो', ',', 'कुछ', 'आवाज़', 'आ', 'रही', 'है', '।', 'फोन', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9AwQoszlyNW"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "raw_data=pd.read_csv('/content/drive/MyDrive/AssignmentNLP/train/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAs-kYJEUom0",
        "outputId": "2b53d4a3-dd9c-46de-bbfe-b47c93b55352"
      },
      "source": [
        "!ls '/content/drive/MyDrive/AssignmentNLP/train/train.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AssignmentNLP/train/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiRzQFpGNqP"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Xa_cybKIU-xZ",
        "outputId": "6a47797d-6a0d-4a39-9888-0db68f19644a"
      },
      "source": [
        "raw_data.head(6)\n",
        "raw_data=raw_data.iloc[:,1:]\n",
        "raw_data.head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध...</td>\n",
              "      <td>In El Salvador, both sides that withdrew from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मैं उनके साथ कोई लेना देना नहीं है.</td>\n",
              "      <td>I have nothing to do with them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-हटाओ रिक.</td>\n",
              "      <td>Fuck them, Rick.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>क्योंकि यह एक खुशियों भरी फ़िल्म है.</td>\n",
              "      <td>Because it's a happy film.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The thought reaching the eyes...</td>\n",
              "      <td>The thought reaching the eyes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मैंने तुमे School से हटवा दिया .</td>\n",
              "      <td>I got you suspended.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>यह Vika, एक फूल है.</td>\n",
              "      <td>It's a flower, Vika.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यो...</td>\n",
              "      <td>But personally, for me, the fact that Picquart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम का...</td>\n",
              "      <td>No, no, no... fine, we'll uh... we'll use the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>- क्या भाषा क्या वे वहाँ बात की?</td>\n",
              "      <td>- What language do they speak there?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               hindi                                            english\n",
              "0  एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध...  In El Salvador, both sides that withdrew from ...\n",
              "1                मैं उनके साथ कोई लेना देना नहीं है.                    I have nothing to do with them.\n",
              "2                                         -हटाओ रिक.                                   Fuck them, Rick.\n",
              "3               क्योंकि यह एक खुशियों भरी फ़िल्म है.                         Because it's a happy film.\n",
              "4                   The thought reaching the eyes...                   The thought reaching the eyes...\n",
              "5                   मैंने तुमे School से हटवा दिया .                               I got you suspended.\n",
              "6                                यह Vika, एक फूल है.                               It's a flower, Vika.\n",
              "7  पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यो...  But personally, for me, the fact that Picquart...\n",
              "8  नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम का...  No, no, no... fine, we'll uh... we'll use the ...\n",
              "9                   - क्या भाषा क्या वे वहाँ बात की?               - What language do they speak there?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43MLTrj3WR69",
        "outputId": "85dd4198-af4c-4381-f367-4a292521ac76"
      },
      "source": [
        "raw_data.hindi.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध...\n",
              "1                  मैं उनके साथ कोई लेना देना नहीं है.\n",
              "2                                           -हटाओ रिक.\n",
              "3                 क्योंकि यह एक खुशियों भरी फ़िल्म है.\n",
              "4                     The thought reaching the eyes...\n",
              "5                     मैंने तुमे School से हटवा दिया .\n",
              "6                                  यह Vika, एक फूल है.\n",
              "7    पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यो...\n",
              "8    नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम का...\n",
              "9                     - क्या भाषा क्या वे वहाँ बात की?\n",
              "Name: hindi, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjm4xIjW-Hv"
      },
      "source": [
        "df = raw_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwAI9_WBXaze"
      },
      "source": [
        "df['hin_len'] = df['hindi'].str.count(' ')\n",
        "df['eng_len'] = df['english'].str.count(' ')\n",
        "df = df.query('hin_len<100 & eng_len<100')\n",
        "df = df.query('hin_len>2  & eng_len>2')\n",
        "df = df.query('hin_len<eng_len*2 & hin_len*2>eng_len')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTS63avhZDxm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# create train and validation set \n",
        "train, val = train_test_split(df, test_size=0.1)\n",
        "train.to_csv(\"/content/drive/MyDrive/train.csv\", index=False)\n",
        "val.to_csv(\"/content/drive/MyDrive/val.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcurR84mbc66"
      },
      "source": [
        "hindi = Field(tokenize=tokenize_hindi, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_english, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "LuAjeuivc3DW",
        "outputId": "064091fa-8e9b-4290-df05-2b13d5a53303"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "      <th>hin_len</th>\n",
              "      <th>eng_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96864</th>\n",
              "      <td>इस गोदाम में सब लोग प्राप्त करने के लिए?</td>\n",
              "      <td>To get everybody into this warehouse?</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23450</th>\n",
              "      <td>क्या आप अब भी ऐसा करना चाहते हैं?</td>\n",
              "      <td>Do you still want to do this?</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>अब, शायद मैं इन्ही शब्दों का उपयोग ना करूं अपन...</td>\n",
              "      <td>Now, I'm not sure if I would use any of these ...</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80468</th>\n",
              "      <td>फ़िर हमने सीमा पार की और सीरिया गये, फ़िर अलेप्प...</td>\n",
              "      <td>Then we crossed the border into Syria, went to...</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46719</th>\n",
              "      <td>देखिए, माफ़ी चाहूँगा, पर हम पूजा के लिए बैठने ह...</td>\n",
              "      <td>Look, I'm so sorry, but we're about to sit dow...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>आज हम अपने दरवाजे पर कर रहे हैं कि राक्षसों का...</td>\n",
              "      <td>Today we face the monsters that are at our door</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53707</th>\n",
              "      <td>मैं तुम्हें कल देखेंगे.</td>\n",
              "      <td>I'll see you tomorrow.</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98251</th>\n",
              "      <td>अभी आपने क्या कहा?</td>\n",
              "      <td>What did you just say?</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13912</th>\n",
              "      <td>सोचो ... जिसका गंतव्य पृष्ठ है नहीं। 65।</td>\n",
              "      <td>Think... whose destination is page no. 65.</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23607</th>\n",
              "      <td>आज के कलाकार जान सकते हैं हम क्या महसूस कर रहे...</td>\n",
              "      <td>Today's artists can know what we're feeling.</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   hindi  ... eng_len\n",
              "96864           इस गोदाम में सब लोग प्राप्त करने के लिए?  ...       5\n",
              "23450                  क्या आप अब भी ऐसा करना चाहते हैं?  ...       6\n",
              "1150   अब, शायद मैं इन्ही शब्दों का उपयोग ना करूं अपन...  ...      23\n",
              "80468  फ़िर हमने सीमा पार की और सीरिया गये, फ़िर अलेप्प...  ...      16\n",
              "46719  देखिए, माफ़ी चाहूँगा, पर हम पूजा के लिए बैठने ह...  ...      11\n",
              "997    आज हम अपने दरवाजे पर कर रहे हैं कि राक्षसों का...  ...       9\n",
              "53707                            मैं तुम्हें कल देखेंगे.  ...       3\n",
              "98251                                 अभी आपने क्या कहा?  ...       4\n",
              "13912           सोचो ... जिसका गंतव्य पृष्ठ है नहीं। 65।  ...       6\n",
              "23607  आज के कलाकार जान सकते हैं हम क्या महसूस कर रहे...  ...       6\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_CK7g8csAo"
      },
      "source": [
        "# associate the text in the 'English' column with the EN_TEXT field, # and 'French' with FR_TEXT\n",
        "from torchtext.data import TabularDataset\n",
        "data_fields = [('hindi', hindi), ('english', english)]\n",
        "train,val = TabularDataset.splits(path='/content/drive/MyDrive/', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAP9CaMSF-fP"
      },
      "source": [
        "# **Creating the English and Hindi Vocabuaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UDyvnZBeDjl"
      },
      "source": [
        "hindi.build_vocab(train, min_freq=2)\n",
        "english.build_vocab(train, min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGy1gjjQfCOl",
        "outputId": "02eb0142-758e-4dfa-a143-b031c56d3a96"
      },
      "source": [
        "print(f\"Unique tokens in source (hi) vocabulary: {len(hindi.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (hi) vocabulary: 19405\n",
            "Unique tokens in target (en) vocabulary: 16903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoE4DSvOfc-_",
        "outputId": "21c6640d-4a5c-4c12-c650-a9ff7f2657ac"
      },
      "source": [
        "hindi.vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.vocab.Vocab at 0x7feeb4087310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FN7ttY-gJnk",
        "outputId": "b4af6e0c-464c-4778-a406-a032d7cc6d8e"
      },
      "source": [
        "print(english.vocab.stoi['the'])\n",
        "print(english.vocab.itos[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70u0qeEyjgRZ",
        "outputId": "0656e78e-8503-4b14-81bf-d18a7898ab65"
      },
      "source": [
        "print(hindi.vocab.itos[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "है\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XV7aeIj0oo"
      },
      "source": [
        "train_iter = BucketIterator(train, batch_size=20, sort_key=lambda x: len(x.hindi), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol_o9fcykOz0"
      },
      "source": [
        "#batch=next(iter(train_iter))\n",
        "#print(batch.hindi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePvsw3SVkkQE"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC7HFWviGU4T"
      },
      "source": [
        "# **Defining the Encoder (LSTM) architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIx0BnVDk-oC"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        " \n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "    return hidden_state, cell_state\n",
        "input_size_encoder = len(hindi.vocab)\n",
        "encoder_embedding_size = 100\n",
        "hidden_size = 512\n",
        "num_layers = 3\n",
        "encoder_dropout = float(0.4)\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,hidden_size, num_layers, encoder_dropout).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVqaFfgfGfgG"
      },
      "source": [
        "# **Defining the Decoder(LSTM) Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCAVyG3XmR2e"
      },
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size  \n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "    x = x.unsqueeze(0)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "    predictions = self.fc(outputs)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(english.vocab)\n",
        "decoder_embedding_size = 100\n",
        "hidden_size = 512\n",
        "num_layers = 3\n",
        "decoder_dropout = float(0.4)\n",
        "output_size = len(english.vocab)\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size, hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0QGgiNZIYHX"
      },
      "source": [
        "# **Defining the Sequence-to-Sequence Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGZ5RyqVmmv9"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5):\n",
        "    batch_size = source.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "    x = target[0] \n",
        "    for i in range(1, target_len):\n",
        "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1)\n",
        "      x = target[i] if random.random() < tfr else best_guess \n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfdOkjvxH9U5"
      },
      "source": [
        "# **Defining Hyperparameters of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgdIZOMinIck"
      },
      "source": [
        "learning_rate = 0.001\n",
        "#writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V9iEzAYvfiW",
        "outputId": "b7333189-d599-4963-a660-7cef2d324698"
      },
      "source": [
        "len(train_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alm1A5P8H5sw"
      },
      "source": [
        "# **Defining Utility funtions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1aW26JfiAgW"
      },
      "source": [
        "def translate_sentence(model, sentence, hindi, english, device, max_length=50):\n",
        "    tokens=tokenize_hindi(sentence)\n",
        "    tokens.insert(0, hindi.init_token)\n",
        "    tokens.append(hindi.eos_token)\n",
        "    text_to_indices = [hindi.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    return translated_sentence[1:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBjGUGMgEGkS"
      },
      "source": [
        "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
        "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
        "    torch.save(state, '/content/drive/MyDrive/checkpoint-week1')\n",
        "    torch.save(model.state_dict(),'/content/drive/MyDrive/checkpoint-state-dict-week1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjqFIF1AH2G5"
      },
      "source": [
        "# **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHesSylSnTVb"
      },
      "source": [
        "epoch_loss = 0.0\n",
        "num_epochs = 100\n",
        "best_loss = 10000000\n",
        "best_epoch = -1\n",
        "sentence1=\"वे कहते हैं कि जहाज पर आप की जरूरत है।\"\n",
        "ts1 = []\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  model.eval()\n",
        "  translated_sentence1 = translate_sentence(model, sentence1, hindi, english, device, max_length=50)\n",
        "  print(translated_sentence1)\n",
        "  ts1.append(translated_sentence1)\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iter):\n",
        "    input = batch.hindi.to(device)\n",
        "    target = batch.english.to(device)\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "    optimizer.zero_grad()       \n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "    #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    best_epoch = epoch\n",
        "    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss)\n",
        "    if ((epoch - best_epoch) >= 10):\n",
        "      print(\"no improvement in 10 epochs, break\")\n",
        "      break\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "print(epoch_loss / len(train_iter))\n",
        "print('------------done---------')\n",
        "\n",
        "#while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdyjPdchErWX"
      },
      "source": [
        "#checkpoint = torch.load('/content/drive/MyDrive/checkpoint-week1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOMXqPnpGOd9"
      },
      "source": [
        "#state=torch.load('/content/drive/MyDrive/checkpoint-state-dict-week1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDd5Z9S8KglD",
        "outputId": "2d233f40-a124-43b1-8893-03f26780c4b9"
      },
      "source": [
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/checkpoint-state-dict-week1'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2nRVrTFLCOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0831d9e-6f51-4bf4-af98-d32fe1d1befc"
      },
      "source": [
        "model.eval()\n",
        "#print(checkpoint['best_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (Encoder_LSTM): EncoderLSTM(\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "    (embedding): Embedding(19405, 100)\n",
              "    (LSTM): LSTM(100, 512, num_layers=3, dropout=0.4)\n",
              "  )\n",
              "  (Decoder_LSTM): DecoderLSTM(\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "    (embedding): Embedding(16903, 100)\n",
              "    (LSTM): LSTM(100, 512, num_layers=3, dropout=0.4)\n",
              "    (fc): Linear(in_features=512, out_features=16903, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRZhGwQOlMYy"
      },
      "source": [
        "model.eval()\n",
        "sentence=\"वे कहते हैं कि जहाज पर आप की जरूरत है।\"\n",
        "translated_sentence = translate_sentence(model, sentence, hindi, english, device, max_length=50)\n",
        "print(translated_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtCKzHEInGIm"
      },
      "source": [
        "#checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lc2CA_8HHW2"
      },
      "source": [
        "# **Generating the translated sentences of the development set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZkeaAoutZMn"
      },
      "source": [
        "\n",
        "hs=pd.read_csv('/content/drive/MyDrive/AssignmentNLP/week2/hindistatements.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RxfDBDd6titb",
        "outputId": "4abdeb5d-e406-4eff-c90a-d63a5e9ce554"
      },
      "source": [
        "hs.head(6)\n",
        "#raw_data=raw_data.iloc[:,1:]\n",
        "#raw_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>कौन वे अपनी आस्तीन ऊपर है क्या अन्य तरकीबें जा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>हम कहानियों के ज़रिये अपने ज्ञान को आगे देते हैं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>फिर वे मुझे भी साथ लाते।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>- हाँ, दुर्भाग्य से.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>मुलाक़ात नहीं हो पाई</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>और जब आप इस बारे में में सोचते हैं, कि हम संयु...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id                                              hindi\n",
              "0           0   0  कौन वे अपनी आस्तीन ऊपर है क्या अन्य तरकीबें जा...\n",
              "1           1   1   हम कहानियों के ज़रिये अपने ज्ञान को आगे देते हैं।\n",
              "2           2   2                           फिर वे मुझे भी साथ लाते।\n",
              "3           3   3                               - हाँ, दुर्भाग्य से.\n",
              "4           4   4                                मुलाक़ात नहीं हो पाई\n",
              "5           5   5  और जब आप इस बारे में में सोचते हैं, कि हम संयु..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ-J7Q5YtyQb",
        "outputId": "2d07c05f-7752-42da-861e-fe469264cf9e"
      },
      "source": [
        "hs.hindi[1]\n",
        "print(len(hs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBToLnr0HUcW"
      },
      "source": [
        "# **Defining the Eglish De-tokenizer** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r1I6CB1t_3H"
      },
      "source": [
        "op=[]\n",
        "for i in range(0,5000):\n",
        "  sentence=hs.hindi[i]\n",
        "  translated_sentence = translate_sentence(model, sentence, hindi, english, device, max_length=50)\n",
        "  ts=''\n",
        "  for wd in translated_sentence:\n",
        "    if wd=='<eos>':\n",
        "      break\n",
        "    if wd=='<unk>':\n",
        "      continue\n",
        "    ts=ts+wd+' '\n",
        "  op.append(ts[:-1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "433Q8ogqDO7p"
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "op2=[]\n",
        "for i in range(0,len(hs)):\n",
        "  sentence=hs.hindi[i]\n",
        "  translated_sentence = translate_sentence(model, sentence, hindi, english, device, max_length=50)\n",
        "  ts=TreebankWordDetokenizer().detokenize(translated_sentence)\n",
        "  op2.append(ts[-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIA82egwwV8X"
      },
      "source": [
        "print(op[0])\n",
        "#print(op2[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY4m2GnDHvEw"
      },
      "source": [
        "# **Saving the outputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_PVJ95whLe"
      },
      "source": [
        "ip=[]\n",
        "for i in range(0,len(hs)):\n",
        "  sentence=hs.hindi[i]\n",
        "  ip.append(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoS4UtjKWt3s"
      },
      "source": [
        "\n",
        "#with open('/content/drive/MyDrive/AssignmentNLP/hin.txt', 'w') as f2:\n",
        "#    for item in op:\n",
        "#        f2.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zMvrguxFV2"
      },
      "source": [
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/english.txt', 'w') as f:\n",
        "    for item in op:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ2Ruxgm0EXK",
        "outputId": "f3139c47-4de3-488c-cd0c-442aa9be841e"
      },
      "source": [
        "!ls '/content/drive/MyDrive/AssignmentNLP'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english.txt  evaluationscript  hindistatements.csv  hin.txt  train  week2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfLGp-CsHiI"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}