{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-lstm-w1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IqW2S5FEl0Q"
      },
      "source": [
        "# **`Checking GPU availability`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA_ierau5Yiq",
        "outputId": "6c01d45d-616f-4165-ea3b-becdc5a8fb6d"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 11 09:50:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-p1ezcbE9Xy"
      },
      "source": [
        "# **Checking RAM availability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twDzSRoA5akd",
        "outputId": "7ded2cd8-ba65-48bc-aa17-4bd69b198273"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2vOYq2-FOZk"
      },
      "source": [
        "# **Importing Libraries and Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiiEqB9jfoPo",
        "outputId": "e906c4c0-3717-412b-f697-3292f48e02b4"
      },
      "source": [
        "!pip install torchtext==0.6.0 --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from pprint import pprint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzqGMrfKgBY_",
        "outputId": "6aae3f46-6144-4d80-aa1d-54da18ea807e"
      },
      "source": [
        "!python -m spacy download en --quiet\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMbYNYEOgr4W",
        "outputId": "3371623b-841d-454b-9f55-18b1a3b63311"
      },
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 2.86 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co3WuyQCj21R",
        "outputId": "7b04c3b5-124e-4bfa-d889-f3a409d18199"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 27.17 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMilEI-AkEVX"
      },
      "source": [
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZwMAo5DkIu_"
      },
      "source": [
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFrXwVlJkMiW"
      },
      "source": [
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkc_LZHBkRAs"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzBkWOmjkh-D",
        "outputId": "2114e3c9-107d-4ed3-e797-8a6286e80822"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "\n",
        "indic_string='सुनो, कुछ आवाज़ आ रही है। फोन?'\n",
        "\n",
        "print('Input String: {}'.format(indic_string))\n",
        "print('Tokens: ')\n",
        "for t in indic_tokenize.trivial_tokenize(indic_string): \n",
        "    print(t)\n",
        "\n",
        "print(indic_tokenize.trivial_tokenize(indic_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input String: सुनो, कुछ आवाज़ आ रही है। फोन?\n",
            "Tokens: \n",
            "सुनो\n",
            ",\n",
            "कुछ\n",
            "आवाज़\n",
            "आ\n",
            "रही\n",
            "है\n",
            "।\n",
            "फोन\n",
            "?\n",
            "['सुनो', ',', 'कुछ', 'आवाज़', 'आ', 'रही', 'है', '।', 'फोन', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI_IDzqeFb8G"
      },
      "source": [
        "# **Mounting Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaTgu_PekttC",
        "outputId": "666c80f8-08b3-407f-f552-403808733df6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "377e9yx_k3AL"
      },
      "source": [
        "spacy_english = spacy.load(\"en\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6rMsqxjFnG5"
      },
      "source": [
        "# **Defining Tokenizers for English (spacy) and Hindi (Indic NLP)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQoG4ibSlXIn"
      },
      "source": [
        "def tokenize_english(text):                  #tokenizer for english using Spacy\n",
        "  return [token.text for token in spacy_english.tokenizer(text)]\n",
        "\n",
        "\n",
        "sample_text = \"I am, going to work\"\n",
        "print(tokenize_english(sample_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqRX3f17lJpA",
        "outputId": "bc28ddb4-4363-4adf-c1ae-8505c9617bf8"
      },
      "source": [
        "def tokenize_hindi(text):                      #tokenizer for hindi using Indic NLP\n",
        "  return indic_tokenize.trivial_tokenize(text)\n",
        "\n",
        "sample_text = 'सुनो, कुछ आवाज़ आ रही है। फोन?'\n",
        "print(tokenize_hindi(sample_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['सुनो', ',', 'कुछ', 'आवाज़', 'आ', 'रही', 'है', '।', 'फोन', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9AwQoszlyNW"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "raw_data=pd.read_csv('/content/drive/MyDrive/AssignmentNLP/train/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAs-kYJEUom0",
        "outputId": "89453c32-fe89-4a55-dc74-e543f5c175e9"
      },
      "source": [
        "!ls '/content/drive/MyDrive/AssignmentNLP/train/train.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AssignmentNLP/train/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiRzQFpGNqP"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Xa_cybKIU-xZ",
        "outputId": "60668051-53f2-46c9-eb90-5e4ce2ae3fbb"
      },
      "source": [
        "raw_data.head(6)\n",
        "raw_data=raw_data.iloc[:,1:]\n",
        "raw_data.head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध...</td>\n",
              "      <td>In El Salvador, both sides that withdrew from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मैं उनके साथ कोई लेना देना नहीं है.</td>\n",
              "      <td>I have nothing to do with them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-हटाओ रिक.</td>\n",
              "      <td>Fuck them, Rick.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>क्योंकि यह एक खुशियों भरी फ़िल्म है.</td>\n",
              "      <td>Because it's a happy film.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The thought reaching the eyes...</td>\n",
              "      <td>The thought reaching the eyes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मैंने तुमे School से हटवा दिया .</td>\n",
              "      <td>I got you suspended.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>यह Vika, एक फूल है.</td>\n",
              "      <td>It's a flower, Vika.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यो...</td>\n",
              "      <td>But personally, for me, the fact that Picquart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम का...</td>\n",
              "      <td>No, no, no... fine, we'll uh... we'll use the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>- क्या भाषा क्या वे वहाँ बात की?</td>\n",
              "      <td>- What language do they speak there?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               hindi                                            english\n",
              "0  एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध...  In El Salvador, both sides that withdrew from ...\n",
              "1                मैं उनके साथ कोई लेना देना नहीं है.                    I have nothing to do with them.\n",
              "2                                         -हटाओ रिक.                                   Fuck them, Rick.\n",
              "3               क्योंकि यह एक खुशियों भरी फ़िल्म है.                         Because it's a happy film.\n",
              "4                   The thought reaching the eyes...                   The thought reaching the eyes...\n",
              "5                   मैंने तुमे School से हटवा दिया .                               I got you suspended.\n",
              "6                                यह Vika, एक फूल है.                               It's a flower, Vika.\n",
              "7  पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यो...  But personally, for me, the fact that Picquart...\n",
              "8  नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम का...  No, no, no... fine, we'll uh... we'll use the ...\n",
              "9                   - क्या भाषा क्या वे वहाँ बात की?               - What language do they speak there?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43MLTrj3WR69",
        "outputId": "fdc8e953-300c-4d7e-9798-456efa238d6a"
      },
      "source": [
        "raw_data.hindi.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध...\n",
              "1                  मैं उनके साथ कोई लेना देना नहीं है.\n",
              "2                                           -हटाओ रिक.\n",
              "3                 क्योंकि यह एक खुशियों भरी फ़िल्म है.\n",
              "4                     The thought reaching the eyes...\n",
              "5                     मैंने तुमे School से हटवा दिया .\n",
              "6                                  यह Vika, एक फूल है.\n",
              "7    पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यो...\n",
              "8    नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम का...\n",
              "9                     - क्या भाषा क्या वे वहाँ बात की?\n",
              "Name: hindi, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjm4xIjW-Hv"
      },
      "source": [
        "df = raw_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwAI9_WBXaze"
      },
      "source": [
        "df['hin_len'] = df['hindi'].str.count(' ')\n",
        "df['eng_len'] = df['english'].str.count(' ')\n",
        "df = df.query('hin_len < 80 & eng_len < 80')\n",
        "df = df.query('hin_len < eng_len * 1.5 & hin_len * 1.5 > eng_len')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTS63avhZDxm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# create train and validation set \n",
        "train, val = train_test_split(df, test_size=0.1)\n",
        "train.to_csv(\"/content/drive/MyDrive/train.csv\", index=False)\n",
        "val.to_csv(\"/content/drive/MyDrive/val.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcurR84mbc66"
      },
      "source": [
        "hindi = Field(tokenize=tokenize_hindi, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_english, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "LuAjeuivc3DW",
        "outputId": "a4b0f40c-b5b3-4068-b59b-0d9e114687dc"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "      <th>hin_len</th>\n",
              "      <th>eng_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35270</th>\n",
              "      <td>मेरे आवासीय पैसे और पासपोर्ट सैन्य मुख्यालय मे...</td>\n",
              "      <td>My housing money and passport are at the milit...</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35382</th>\n",
              "      <td>खैर, मैं तुम्हें क्या मतलब पता नहीं है.</td>\n",
              "      <td>Well, I don't know what you mean.</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70205</th>\n",
              "      <td>डर अब डर नहीं रहा |</td>\n",
              "      <td>The fear is no longer fear.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46636</th>\n",
              "      <td>अपना सिर नीचे कीजिए !</td>\n",
              "      <td>Get your head down!</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69632</th>\n",
              "      <td>मैं डौग नहीं देखा था.</td>\n",
              "      <td>I didn't see Doug.</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22856</th>\n",
              "      <td>मैं मानता हूँ, पहली नजर में मुझे एंडी कोई खास ...</td>\n",
              "      <td>I must admit, I didn't think much of Andy, fir...</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70495</th>\n",
              "      <td>बिल्कुल प्रतिभाशाली!</td>\n",
              "      <td>Absolutely brilliant!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48931</th>\n",
              "      <td>27 मार्च को, भारतीय रिजर्व बैंक ने लॉकडाउन के ...</td>\n",
              "      <td>On 27 March, the Reserve Bank of India announc...</td>\n",
              "      <td>23</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52652</th>\n",
              "      <td>(हंसी) अच्छा। दूसरी तरफ कुंजीपटल पर एक अलग स्थ...</td>\n",
              "      <td>(Laughter) Placing your finger at different pl...</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93175</th>\n",
              "      <td>अपने क़रीबियों को पास खींच लूँगी, हमारे गीत हम...</td>\n",
              "      <td>Gather my beloved near, and our chanting will ...</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   hindi  ... eng_len\n",
              "35270  मेरे आवासीय पैसे और पासपोर्ट सैन्य मुख्यालय मे...  ...       9\n",
              "35382            खैर, मैं तुम्हें क्या मतलब पता नहीं है.  ...       6\n",
              "70205                                डर अब डर नहीं रहा |  ...       5\n",
              "46636                              अपना सिर नीचे कीजिए !  ...       3\n",
              "69632                              मैं डौग नहीं देखा था.  ...       3\n",
              "22856  मैं मानता हूँ, पहली नजर में मुझे एंडी कोई खास ...  ...      15\n",
              "70495                               बिल्कुल प्रतिभाशाली!  ...       1\n",
              "48931  27 मार्च को, भारतीय रिजर्व बैंक ने लॉकडाउन के ...  ...      21\n",
              "52652  (हंसी) अच्छा। दूसरी तरफ कुंजीपटल पर एक अलग स्थ...  ...      22\n",
              "93175  अपने क़रीबियों को पास खींच लूँगी, हमारे गीत हम...  ...       9\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_CK7g8csAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "f0b8db67-f994-40fa-840c-2e9724eb7d44"
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "data_fields = [('hindi', hindi), ('english', english)]\n",
        "train,val = TabularDataset.splits(path='/content/drive/MyDrive/', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7904eafe0b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hindi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhindi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TabularDataset' from 'torchtext.data' (/usr/local/lib/python3.7/dist-packages/torchtext/data/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAP9CaMSF-fP"
      },
      "source": [
        "# **Creating the English and Hindi Vocabuaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UDyvnZBeDjl"
      },
      "source": [
        "hindi.build_vocab(train, max_size=10000, min_freq=3)\n",
        "english.build_vocab(train, max_size=10000, min_freq=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGy1gjjQfCOl",
        "outputId": "60a52aba-534d-456d-c969-06f8a8a1501c"
      },
      "source": [
        "print(f\"Unique tokens in source (hi) vocabulary: {len(hindi.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (hi) vocabulary: 10004\n",
            "Unique tokens in target (en) vocabulary: 10004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoE4DSvOfc-_",
        "outputId": "e1a98700-c0ad-4628-e98e-0537668dbaea"
      },
      "source": [
        "hindi.vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.vocab.Vocab at 0x7fd6163b0950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FN7ttY-gJnk",
        "outputId": "62935beb-43c0-46c0-f01f-7dc3cabcdff8"
      },
      "source": [
        "print(english.vocab.stoi['the'])\n",
        "print(english.vocab.itos[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70u0qeEyjgRZ",
        "outputId": "e707473c-07b3-4c0f-e8e8-1371ea0b09b2"
      },
      "source": [
        "print(hindi.vocab.itos[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "है\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XV7aeIj0oo"
      },
      "source": [
        "train_iter = BucketIterator(train, batch_size=20, sort_key=lambda x: len(x.hindi), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol_o9fcykOz0"
      },
      "source": [
        "#batch=next(iter(train_iter))\n",
        "#print(batch.hindi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePvsw3SVkkQE"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC7HFWviGU4T"
      },
      "source": [
        "# **Defining the Encoder (LSTM) architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIx0BnVDk-oC"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        " \n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        " def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "    return hidden_state, cell_state\n",
        "input_size_encoder = len(hindi.vocab)\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 1240\n",
        "num_layers = 2\n",
        "encoder_dropout = float(0.5)\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,hidden_size, num_layers, encoder_dropout).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVqaFfgfGfgG"
      },
      "source": [
        "# **Defining the Decoder(LSTM) Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCAVyG3XmR2e"
      },
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size  \n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "    x = x.unsqueeze(0)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "    predictions = self.fc(outputs)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(english.vocab)\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1240\n",
        "num_layers = 2\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = len(english.vocab)\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size, hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0QGgiNZIYHX"
      },
      "source": [
        "# **Defining the Sequence-to-Sequence Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGZ5RyqVmmv9"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5):\n",
        "    batch_size = source.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "    x = target[0] \n",
        "    for i in range(1, target_len):\n",
        "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1)\n",
        "      x = target[i] if random.random() < tfr else best_guess \n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfdOkjvxH9U5"
      },
      "source": [
        "# **Defining Hyperparameters of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgdIZOMinIck"
      },
      "source": [
        "learning_rate = 0.001\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V9iEzAYvfiW",
        "outputId": "e5406054-7f50-4cac-a8ea-f2a6b5f3cd13"
      },
      "source": [
        "len(train_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alm1A5P8H5sw"
      },
      "source": [
        "# **Defining Utility funtions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1aW26JfiAgW"
      },
      "source": [
        "def translate_sentence(model, sentence, hindi, english, device, max_length=50):\n",
        "    tokens=tokenize_hindi(sentence)\n",
        "    tokens.insert(0, hindi.init_token)\n",
        "    tokens.append(hindi.eos_token)\n",
        "    text_to_indices = [hindi.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    return translated_sentence[1:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBjGUGMgEGkS"
      },
      "source": [
        "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
        "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
        "    torch.save(state, '/content/drive/MyDrive/checkpoint-week1')\n",
        "    torch.save(model.state_dict(),'/content/drive/MyDrive/checkpoint-state-dict-week1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjqFIF1AH2G5"
      },
      "source": [
        "# **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zHesSylSnTVb",
        "outputId": "abb2780e-c338-4c38-bcb6-86ebad3f6d73"
      },
      "source": [
        "epoch_loss = 0.0\n",
        "num_epochs = 100\n",
        "best_loss = 10000000\n",
        "best_epoch = -1\n",
        "sentence1=\"वे कहते हैं कि जहाज पर आप की जरूरत है।\"\n",
        "ts1 = []\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  model.eval()\n",
        "  translated_sentence1 = translate_sentence(model, sentence1, hindi, english, device, max_length=50)\n",
        "  print(translated_sentence1)\n",
        "  ts1.append(translated_sentence1)\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iter):\n",
        "    input = batch.hindi.to(device)\n",
        "    target = batch.english.to(device)\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    best_epoch = epoch\n",
        "    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss)\n",
        "    if ((epoch - best_epoch) >= 10):\n",
        "      print(\"no improvement in 10 epochs, break\")\n",
        "      break\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "print(epoch_loss / len(train_iter))\n",
        "print('------------done---------')\n",
        "\n",
        "#while True:pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 1 / 100\n",
            "['prints', 'banker', 'prints', 'banker', 'prints', 'banker', 'prints', 'centered', 'revati', 'technique', 'generals', 'huh', 'aye', 'aye', 'backs', 'aye', 'proof', 'filed', 'filed', 'mostly', '764', 'strongly', 'aye', 'aye', 'shield', 'dear', 'dear', 'served', 'mr', 'mr', 'infrastructures', 'infrastructures', 'yelled', 'yelled', 'icy', 'urge', 'unlikely', 'municipal', 'theater', 'davide', 'slaves', 'slaves', '2.0', 'talents', 'wilson', 'wilson', 'cooperate', 'cooperate', 'cooperate', 'massively']\n",
            "saving\n",
            "\n",
            "Epoch_Loss - 5.542184829711914\n",
            "\n",
            "Epoch - 2 / 100\n",
            "['-', ',', ',', ',', ',', ',', ',', ',', ',', 'and', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 4.983816146850586\n",
            "\n",
            "Epoch - 3 / 100\n",
            "['they', \"'re\", \"n't\", 'to', 'to', 'the', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 4.582911491394043\n",
            "\n",
            "Epoch - 4 / 100\n",
            "['they', \"'re\", 'to', 'to', 'to', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch_Loss - 4.643487453460693\n",
            "\n",
            "Epoch - 5 / 100\n",
            "['they', \"'re\", 'to', 'to', 'you', 'you', 'to', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 4.524116516113281\n",
            "\n",
            "Epoch - 6 / 100\n",
            "['they', \"'re\", 'to', 'to', 'to', 'to', 'to', 'to', '.', '.', '<eos>']\n",
            "Epoch_Loss - 4.386142730712891\n",
            "\n",
            "Epoch - 7 / 100\n",
            "['they', \"'re\", 'going', 'to', 'be', 'you', 'to', '.', '.', '<eos>']\n",
            "Epoch_Loss - 4.252058029174805\n",
            "\n",
            "Epoch - 8 / 100\n",
            "['they', \"'re\", 'going', 'to', 'be', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 4.232497692108154\n",
            "\n",
            "Epoch - 9 / 100\n",
            "['they', \"'re\", 'to', 'to', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 4.011167526245117\n",
            "\n",
            "Epoch - 10 / 100\n",
            "['they', \"'re\", 'to', 'to', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.876671075820923\n",
            "\n",
            "Epoch - 11 / 100\n",
            "['they', \"'re\", 'going', 'to', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 4.094435214996338\n",
            "\n",
            "Epoch - 12 / 100\n",
            "['they', \"'re\", 'the', 'only', 'way', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.4716343879699707\n",
            "\n",
            "Epoch - 13 / 100\n",
            "['they', \"'re\", 'the', 'to', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.5066747665405273\n",
            "\n",
            "Epoch - 14 / 100\n",
            "['they', 'say', 'that', 'you', 'have', 'to', 'to', '.', '.', '<eos>']\n",
            "Epoch_Loss - 3.7709879875183105\n",
            "\n",
            "Epoch - 15 / 100\n",
            "['they', \"'re\", 'the', 'you', 'you', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.446021795272827\n",
            "\n",
            "Epoch - 16 / 100\n",
            "['they', \"'ve\", 'you', 'you', 'to', 'be', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.512751579284668\n",
            "\n",
            "Epoch - 17 / 100\n",
            "['they', \"'ve\", 'got', 'to', 'you', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 2.973724126815796\n",
            "\n",
            "Epoch - 18 / 100\n",
            "['they', 'say', 'you', 'can', 'have', 'to', 'be', '.', '.', '<eos>']\n",
            "Epoch_Loss - 3.4775378704071045\n",
            "\n",
            "Epoch - 19 / 100\n",
            "['they', 'say', 'you', 'need', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.8974008560180664\n",
            "\n",
            "Epoch - 20 / 100\n",
            "['they', 'need', 'to', 'to', 'you', 'you', 'to', '.', '<eos>']\n",
            "Epoch_Loss - 3.725111722946167\n",
            "\n",
            "Epoch - 21 / 100\n",
            "['they', 'say', 'you', 'have', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 3.624035120010376\n",
            "\n",
            "Epoch - 22 / 100\n",
            "['they', 'say', 'you', 'trust', 'you', 'fraud', 'is', '.', '<eos>']\n",
            "Epoch_Loss - 3.5140388011932373\n",
            "\n",
            "Epoch - 23 / 100\n",
            "['they', 'have', 'to', 'to', 'to', 'the', 'deer', '.', '.', '<eos>']\n",
            "Epoch_Loss - 3.116994857788086\n",
            "\n",
            "Epoch - 24 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'you', 'to', '.', '<eos>']\n",
            "Epoch_Loss - 3.0160295963287354\n",
            "\n",
            "Epoch - 25 / 100\n",
            "['they', 'say', 'you', 'have', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 3.0678086280822754\n",
            "\n",
            "Epoch - 26 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'happy', 'to', '<eos>']\n",
            "Epoch_Loss - 3.298454999923706\n",
            "\n",
            "Epoch - 27 / 100\n",
            "['they', 'want', 'to', 'to', 'belong', 'to', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.915178060531616\n",
            "\n",
            "Epoch - 28 / 100\n",
            "['they', 'say', 'you', 'chose', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 3.2934110164642334\n",
            "\n",
            "Epoch - 29 / 100\n",
            "['they', 'say', 'you', 'to', 'be', 'the', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 3.152078151702881\n",
            "\n",
            "Epoch - 30 / 100\n",
            "['they', 'want', 'to', 'to', 'you', 'you', 'want', '.', '<eos>']\n",
            "Epoch_Loss - 2.8838016986846924\n",
            "\n",
            "Epoch - 31 / 100\n",
            "['they', 'need', 'to', 'to', 'to', 'the', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 3.1119093894958496\n",
            "\n",
            "Epoch - 32 / 100\n",
            "['they', 'say', 'you', 'to', 'have', 'to', 'stopped', '.', '<eos>']\n",
            "Epoch_Loss - 3.048595905303955\n",
            "\n",
            "Epoch - 33 / 100\n",
            "['they', 'want', 'to', 'to', 'to', 'to', 'to', '<eos>']\n",
            "Epoch_Loss - 2.8362720012664795\n",
            "\n",
            "Epoch - 34 / 100\n",
            "['they', 'need', 'to', 'to', 'to', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.1000654697418213\n",
            "\n",
            "Epoch - 35 / 100\n",
            "['they', 'need', 'to', 'to', 'to', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.213270902633667\n",
            "\n",
            "Epoch - 36 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 3.644779682159424\n",
            "\n",
            "Epoch - 37 / 100\n",
            "['they', 'wanted', 'to', 'to', 'to', 'the', 'center', '.', '<eos>']\n",
            "Epoch_Loss - 2.9963207244873047\n",
            "\n",
            "Epoch - 38 / 100\n",
            "['they', 'say', 'you', 'to', 'have', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.5355379581451416\n",
            "\n",
            "Epoch - 39 / 100\n",
            "['they', 'say', 'you', 'need', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.2633278369903564\n",
            "\n",
            "Epoch - 40 / 100\n",
            "['they', 'say', 'you', 'have', 'to', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 2.365701198577881\n",
            "\n",
            "Epoch - 41 / 100\n",
            "['they', 'say', 'you', 'to', 'have', 'some', 'power', '.', '<eos>']\n",
            "Epoch_Loss - 3.0749430656433105\n",
            "\n",
            "Epoch - 42 / 100\n",
            "['they', 'say', 'you', 'you', 'need', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 2.0817387104034424\n",
            "\n",
            "Epoch - 43 / 100\n",
            "['they', 'say', 'you', 'you', 'need', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 2.4209818840026855\n",
            "\n",
            "Epoch - 44 / 100\n",
            "['they', 'say', 'you', 'need', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.781540632247925\n",
            "\n",
            "Epoch - 45 / 100\n",
            "['they', 'say', 'you', 'you', 'want', 'to', 'belong', '.', '<eos>']\n",
            "Epoch_Loss - 2.6486592292785645\n",
            "\n",
            "Epoch - 46 / 100\n",
            "['they', 'say', 'you', 'say', 'the', 'you', 'wants', 'to', 'survive', '.', '<eos>']\n",
            "Epoch_Loss - 2.3131051063537598\n",
            "\n",
            "Epoch - 47 / 100\n",
            "['they', 'assume', 'you', 'want', 'to', 'to', 'take', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.331549644470215\n",
            "\n",
            "Epoch - 48 / 100\n",
            "['they', 'believe', 'you', 'to', 'have', 'to', 'pay', '.', '<eos>']\n",
            "Epoch_Loss - 2.1060667037963867\n",
            "\n",
            "Epoch - 49 / 100\n",
            "['they', 'say', 'you', 'risks', 'is', 'you', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 2.4864537715911865\n",
            "\n",
            "Epoch - 50 / 100\n",
            "['they', 'say', 'you', 'to', 'have', 'to', 'near', 'the', '<eos>']\n",
            "Epoch_Loss - 2.5899271965026855\n",
            "\n",
            "Epoch - 51 / 100\n",
            "['they', 'want', 'want', 'to', 'see', 'you', 'to', 'healthy', '<eos>']\n",
            "Epoch_Loss - 2.669804811477661\n",
            "\n",
            "Epoch - 52 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 2.2878010272979736\n",
            "\n",
            "Epoch - 53 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'the', 'dirty', '.', '<eos>']\n",
            "Epoch_Loss - 2.1727030277252197\n",
            "\n",
            "Epoch - 54 / 100\n",
            "['they', 'say', 'you', 'you', 'want', 'to', 'forget', 'the', 'monday', '.', '<eos>']\n",
            "Epoch_Loss - 2.4523348808288574\n",
            "\n",
            "Epoch - 55 / 100\n",
            "['they', 'say', 'you', 'you', 'want', 'to', 'be', 'near', '<eos>']\n",
            "Epoch_Loss - 2.6756045818328857\n",
            "\n",
            "Epoch - 56 / 100\n",
            "['they', 'say', 'you', 'drop', 'you', 'you', 'near', '<eos>']\n",
            "Epoch_Loss - 2.79070782661438\n",
            "\n",
            "Epoch - 57 / 100\n",
            "['they', 'say', 'you', 'have', 'to', 'want', 'drives', 'the', '<eos>']\n",
            "Epoch_Loss - 2.6242852210998535\n",
            "\n",
            "Epoch - 58 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'happy', 'near', '<eos>']\n",
            "Epoch_Loss - 1.9369720220565796\n",
            "\n",
            "Epoch - 59 / 100\n",
            "['they', 'want', 'to', 'drop', 'to', 'you', 'near', 'the', 'near', '.', '<eos>']\n",
            "Epoch_Loss - 2.098785877227783\n",
            "\n",
            "Epoch - 60 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 2.888970136642456\n",
            "\n",
            "Epoch - 61 / 100\n",
            "['they', 'want', 'want', 'to', 'risk', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 2.203310489654541\n",
            "\n",
            "Epoch - 62 / 100\n",
            "['they', 'say', 'you', 'kind', 'of', 'want', 'you', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 2.2130496501922607\n",
            "\n",
            "Epoch - 63 / 100\n",
            "['they', 'want', 'want', 'to', 'trade', 'the', 'market', '<eos>']\n",
            "Epoch_Loss - 1.8516077995300293\n",
            "\n",
            "Epoch - 64 / 100\n",
            "['they', 'cooked', 'you', 'to', 'be', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 1.7255536317825317\n",
            "\n",
            "Epoch - 65 / 100\n",
            "['they', 'assume', 'you', 'to', 'be', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 2.179835081100464\n",
            "\n",
            "Epoch - 66 / 100\n",
            "['they', 'say', 'you', 'want', 'to', 'to', 'pay', 'the', '<eos>']\n",
            "Epoch_Loss - 1.582595944404602\n",
            "\n",
            "Epoch - 67 / 100\n",
            "['they', 'need', 'you', 'to', 'be', 'the', 'radio', '.', '<eos>']\n",
            "Epoch_Loss - 2.100835084915161\n",
            "\n",
            "Epoch - 68 / 100\n",
            "['they', 'say', 'you', 'want', 'you', 'to', 'be', 'safe', '.', '<eos>']\n",
            "Epoch_Loss - 2.0903642177581787\n",
            "\n",
            "Epoch - 69 / 100\n",
            "['they', 'likes', 'to', 'to', 'you', 'want', 'sick', '.', '<eos>']\n",
            "Epoch_Loss - 2.4082212448120117\n",
            "\n",
            "Epoch - 70 / 100\n",
            "['they', 'want', 'want', 'to', 'be', 'you', 'to', '<eos>']\n",
            "Epoch_Loss - 1.713924765586853\n",
            "\n",
            "Epoch - 71 / 100\n",
            "['they', 'say', 'they', 'want', 'to', 'to', 'be', '<eos>']\n",
            "Epoch_Loss - 1.9042421579360962\n",
            "\n",
            "Epoch - 72 / 100\n",
            "['they', 'want', 'want', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.9196131229400635\n",
            "\n",
            "Epoch - 73 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'nice', '.', '<eos>']\n",
            "Epoch_Loss - 2.033662796020508\n",
            "\n",
            "Epoch - 74 / 100\n",
            "['they', 'cooked', 'themselves', 'because', 'you', 'want', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 2.2437846660614014\n",
            "\n",
            "Epoch - 75 / 100\n",
            "['they', 'want', 'want', 'to', 'be', 'getting', 'the', 'pay', '<eos>']\n",
            "Epoch_Loss - 2.1452536582946777\n",
            "\n",
            "Epoch - 76 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.911336064338684\n",
            "\n",
            "Epoch - 77 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.2033193111419678\n",
            "\n",
            "Epoch - 78 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'on', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.9508060216903687\n",
            "\n",
            "Epoch - 79 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'the', 'doctor', '.', '<eos>']\n",
            "Epoch_Loss - 1.7841053009033203\n",
            "\n",
            "Epoch - 80 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'the', 'sick', '.', '<eos>']\n",
            "Epoch_Loss - 1.5114134550094604\n",
            "\n",
            "Epoch - 81 / 100\n",
            "['they', 'want', 'want', 'to', 'have', 'the', 'the', '<eos>']\n",
            "Epoch_Loss - 1.7527680397033691\n",
            "\n",
            "Epoch - 82 / 100\n",
            "['they', 'want', 'want', 'to', 'have', 'money', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 1.9663853645324707\n",
            "\n",
            "Epoch - 83 / 100\n",
            "['they', 'want', 'to', 'to', 'have', 'you', 'to', '<eos>']\n",
            "Epoch_Loss - 1.6813308000564575\n",
            "\n",
            "Epoch - 84 / 100\n",
            "['they', 'want', 'themselves', 'to', 'be', 'the', 'doctor', '.', '<eos>']\n",
            "Epoch_Loss - 2.247168779373169\n",
            "\n",
            "Epoch - 85 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'getting', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.5991926193237305\n",
            "\n",
            "Epoch - 86 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'the', 'sick', '.', '<eos>']\n",
            "Epoch_Loss - 1.620399832725525\n",
            "\n",
            "Epoch - 87 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'getting', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.2309882640838623\n",
            "\n",
            "Epoch - 88 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'getting', 'sick', '.', '<eos>']\n",
            "Epoch_Loss - 2.1309561729431152\n",
            "\n",
            "Epoch - 89 / 100\n",
            "['they', 'want', 'to', 'to', 'have', 'you', 'to', '<eos>']\n",
            "Epoch_Loss - 1.433644413948059\n",
            "\n",
            "Epoch - 90 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'the', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.8964433670043945\n",
            "\n",
            "Epoch - 91 / 100\n",
            "['they', 'want', 'you', 'to', 'have', 'the', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.4418764114379883\n",
            "\n",
            "Epoch - 92 / 100\n",
            "['they', 'wanted', 'to', 'to', 'be', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.434091567993164\n",
            "\n",
            "Epoch - 93 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'you', 'want', '<eos>']\n",
            "Epoch_Loss - 1.8407738208770752\n",
            "\n",
            "Epoch - 94 / 100\n",
            "['they', 'wanted', 'you', 'to', 'be', 'forget', 'the', '<eos>']\n",
            "Epoch_Loss - 1.350682258605957\n",
            "\n",
            "Epoch - 95 / 100\n",
            "['they', 'want', 'to', 'to', 'be', 'you', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 2.1980459690093994\n",
            "\n",
            "Epoch - 96 / 100\n",
            "['they', 'want', 'you', 'to', 'be', 'the', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 1.5435786247253418\n",
            "\n",
            "Epoch - 97 / 100\n",
            "['they', 'say', 'you', 'want', 'you', 'to', 'be', '.', '<eos>']\n",
            "Epoch_Loss - 1.530395746231079\n",
            "\n",
            "Epoch - 98 / 100\n",
            "['they', 'wanted', 'to', 'to', 'be', 'the', 'the', 'you', '.', '<eos>']\n",
            "Epoch_Loss - 1.4082399606704712\n",
            "\n",
            "Epoch - 99 / 100\n",
            "['they', 'wanted', 'you', 'to', 'be', 'getting', 'the', '.', '<eos>']\n",
            "Epoch_Loss - 2.0006558895111084\n",
            "\n",
            "Epoch - 100 / 100\n",
            "['they', 'want', 'want', 'to', 'be', 'the', 'right', '.', '<eos>']\n",
            "Epoch_Loss - 1.2547857761383057\n",
            "\n",
            "257.29450699404345\n",
            "------------done---------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c758d06ff001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------done---------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdyjPdchErWX"
      },
      "source": [
        "#checkpoint = torch.load('/content/drive/MyDrive/checkpoint-week1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOMXqPnpGOd9"
      },
      "source": [
        "#state=torch.load('/content/drive/MyDrive/checkpoint-state-dict-week1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDd5Z9S8KglD",
        "outputId": "2d233f40-a124-43b1-8893-03f26780c4b9"
      },
      "source": [
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/checkpoint-state-dict-week1'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2nRVrTFLCOe"
      },
      "source": [
        "model.eval()\n",
        "#print(checkpoint['best_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRZhGwQOlMYy"
      },
      "source": [
        "model.eval()\n",
        "sentence=\"वे कहते हैं कि जहाज पर आप की जरूरत है।\"\n",
        "translated_sentence = translate_sentence(model, sentence, hindi, english, device, max_length=50)\n",
        "print(translated_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtCKzHEInGIm"
      },
      "source": [
        "#checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lc2CA_8HHW2"
      },
      "source": [
        "# **Generating the translated sentences of the development set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZkeaAoutZMn"
      },
      "source": [
        "\n",
        "hs=pd.read_csv('/content/drive/MyDrive/AssignmentNLP/hindistatements.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RxfDBDd6titb",
        "outputId": "98fd3efc-9ddf-4422-8b0a-12021ac737a5"
      },
      "source": [
        "hs.head(6)\n",
        "#raw_data=raw_data.iloc[:,1:]\n",
        "#raw_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>- अंतरिक्ष वाले लोग?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>आंटी ,ये खबर आपको ही बताना पड़ेगा.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>वे आते और फिल्म देखते।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>मैं जानता हूँ आप क्या सोच रहे हैं। आप सोच रहे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>अगर मैं भी मुझे से चोरी करते हैं, बाकी में सोच...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>बिदका घोड़ा पिछली टांगों पर खड़ा हुआ, छठे स्था...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id                                              hindi\n",
              "0           0   0                               - अंतरिक्ष वाले लोग?\n",
              "1           1   1                 आंटी ,ये खबर आपको ही बताना पड़ेगा.\n",
              "2           2   2                             वे आते और फिल्म देखते।\n",
              "3           3   3  मैं जानता हूँ आप क्या सोच रहे हैं। आप सोच रहे ...\n",
              "4           4   4  अगर मैं भी मुझे से चोरी करते हैं, बाकी में सोच...\n",
              "5           5   5  बिदका घोड़ा पिछली टांगों पर खड़ा हुआ, छठे स्था..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ-J7Q5YtyQb",
        "outputId": "462ea6a7-3747-480a-880c-11db5497b4ac"
      },
      "source": [
        "hs.hindi[1]\n",
        "print(len(hs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBToLnr0HUcW"
      },
      "source": [
        "# **Defining the Eglish De-tokenizer** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r1I6CB1t_3H"
      },
      "source": [
        "op=[]\n",
        "for i in range(0,5000):\n",
        "  sentence=hs.hindi[i]\n",
        "  translated_sentence = translate_sentence(model, sentence, hindi, english, device, max_length=50)\n",
        "  ts=''\n",
        "  for wd in translated_sentence:\n",
        "    if wd=='<eos>':\n",
        "      break\n",
        "    if wd=='<unk>':\n",
        "      continue\n",
        "    ts=ts+wd+' '\n",
        "  op.append(ts[:-1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "433Q8ogqDO7p"
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "op2=[]\n",
        "for i in range(0,len(hs)):\n",
        "  sentence=hs.hindi[i]\n",
        "  translated_sentence = translate_sentence(model, sentence, hindi, english, device, max_length=50)\n",
        "  ts=TreebankWordDetokenizer().detokenize(translated_sentence)\n",
        "  op2.append(ts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIA82egwwV8X",
        "outputId": "197ed353-3db6-4276-e493-f726a5195477"
      },
      "source": [
        "print(op[0])\n",
        "print(op2[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get laughing goals flying town .\n",
            "get laughing goals flying town . <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY4m2GnDHvEw"
      },
      "source": [
        "# **Saving the outputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_PVJ95whLe"
      },
      "source": [
        "ip=[]\n",
        "for i in range(0,len(hs)):\n",
        "  sentence=hs.hindi[i]\n",
        "  ip.append(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoS4UtjKWt3s"
      },
      "source": [
        "\n",
        "#with open('/content/drive/MyDrive/AssignmentNLP/hin.txt', 'w') as f2:\n",
        "#    for item in op:\n",
        "#        f2.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zMvrguxFV2"
      },
      "source": [
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/english.txt', 'w') as f:\n",
        "    for item in op:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ2Ruxgm0EXK",
        "outputId": "15c8d072-fec5-4445-e32b-2288dd43a70b"
      },
      "source": [
        "!ls '/content/drive/MyDrive/AssignmentNLP'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english.txt  evaluationscript  hindistatements.csv  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "VKfLGp-CsHiI",
        "outputId": "9050847e-61fe-4f21-8c89-b525624307d2"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-534b7a74019f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}